{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pip install pymupdf\n","pip install einops flash_attn\n","pip install python-docx"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import fitz  \n","from PIL import Image, ImageDraw, ImageFont\n","import io\n","from io import BytesIO\n","import pytesseract  \n","import torch \n","import requests  \n","from transformers import Blip2Processor, Blip2ForConditionalGeneration, PegasusForConditionalGeneration, PegasusTokenizer, AutoProcessor, AutoModelForCausalLM \n","from docx import Document \n","from docx.shared import Inches  \n","import tempfile  \n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","from transformers import BartForConditionalGeneration, BartTokenizer\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from transformers import BartTokenizer\n","import numpy as np \n","import pandas as pd \n","nltk.download('punkt')\n","nltk.download('stopwords')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = AutoModelForCausalLM.from_pretrained(\"microsoft/Florence-2-large\", trust_remote_code=True).to(device)\n","processor = AutoProcessor.from_pretrained(\"microsoft/Florence-2-large\", trust_remote_code=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def run_example(image, task_prompt, text_input=None):\n","    if text_input is None:\n","        prompt = task_prompt\n","    else:\n","        prompt = task_prompt + text_input\n","    inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(device)\n","    generated_ids = model.generate(\n","        input_ids=inputs[\"input_ids\"],\n","        pixel_values=inputs[\"pixel_values\"],\n","        max_new_tokens=1024,\n","        num_beams=3\n","    )\n","    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n","    parsed_answer = processor.post_process_generation(generated_text, task=task_prompt, image_size=(image.width, image.height))\n","    caption = parsed_answer[\"<MORE_DETAILED_CAPTION>\"]\n","    return caption"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def pdf_doc(pdf_document):\n","    doc = fitz.open(pdf_document)\n","\n","    page_text_list = []\n","    for page_number in range(len(doc)):\n","        page = doc.load_page(page_number)  \n","        image_list = page.get_images(full=True)  \n","\n","        page_text = page.get_text()\n","        page_text_combined = page_text\n","\n","        \n","        for img_index, img in enumerate(image_list):\n","            xref = img[0] \n","            base_image = doc.extract_image(xref)  \n","            image_bytes = base_image[\"image\"]\n","            \n","            image = Image.open(io.BytesIO(image_bytes)).convert('RGB')\n","            \n","            prompt = \"<MORE_DETAILED_CAPTION>\"\n","            generated_caption = run_example(image, prompt)\n","\n","            combined_text = f\"\\n\\nImage {img_index + 1}:\\nCaption: {generated_caption}\\n\"\n","\n","            page_text_combined += combined_text\n","\n","        page_text_list.append(page_text_combined)\n","    return page_text_list"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def docx_doc(docx_document):\n","    doc = Document(docx_document)\n","    doc_text_list = []\n","    for para in doc.paragraphs:\n","        doc_text_list.append(para.text)\n","\n","        for run in para.runs:\n","            if run.element.xml.find(\"pic:blipFill\") != -1:\n","                image = run.element.xpath(\".//a:blip\")[0]\n","                image_data = image.get(\"{http://schemas.openxmlformats.org/officeDocument/2006/relationships}embed\")\n","                image_part = doc.part.related_parts[image_data]\n","                image_bytes = image_part.blob\n","\n","                image = Image.open(io.BytesIO(image_bytes)).convert('RGB')\n","                prompt = \"<MORE_DETAILED_CAPTION>\"\n","                generated_caption = run_example(image, prompt)\n","                combined_text = f\"Caption: {generated_caption}\\n\"\n","                doc_text_list.append(combined_text)\n","    return doc_text_list\n","\n","    \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def determine_file_type(file_path):\n","    _, file_extension = os.path.splitext(file_path)\n","    if file_extension.lower() == '.docx':\n","        return 'docx'\n","    elif file_extension.lower() == '.pdf':\n","        return 'pdf'\n","    else:\n","        return 'unknown'"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_text(path):\n","    text_each_page=[]\n","    file_type=determine_file_type(path)\n","    if file_type=='pdf':\n","        text_each_page=pdf_doc(path)\n","    elif file_type=='docx':\n","        text_each_page=docx_doc(path)\n","    else :\n","        print(\"invalid file type\")\n","    return text_each_page"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def preprocess_text(text):\n","    text = text.lower()\n","    tokens = word_tokenize(text)\n","    stop_words = set(stopwords.words('english'))\n","    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n","    return ' '.join(tokens)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def process_text_in_sentence_chunks(path, max_chunk_size):\n","    text=('\\n'.join(page for page in get_text(path)))\n","    sentences = text.replace(\"\\n\", \" \") \n","    sentences = nltk.sent_tokenize(sentences)\n","\n","    current_chunk = \"\"\n","    text_list = []\n","    for sentence in sentences:\n","        if len(current_chunk) + len(sentence) <= max_chunk_size:\n","            current_chunk += \" \" + sentence\n","        else:\n","              text_list.append(current_chunk.strip())\n","              current_chunk = sentence\n","\n","    if current_chunk:\n","        text_list.append(current_chunk.strip())\n","    return text_list"]},{"cell_type":"markdown","metadata":{},"source":["# Models****"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_name = 't5-large'\n","tokenizer1 = T5Tokenizer.from_pretrained(model_name)\n","model1 = T5ForConditionalGeneration.from_pretrained(model_name)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model1.to(device)\n","\n","def generate_summary_t5(text, max_length=60):\n","    preprocess_text = text.strip().replace(\"\\n\", \" \")\n","    t5_prepared_text = \"summarize: \" + preprocess_text\n","\n","    tokenized_text = tokenizer1.encode(t5_prepared_text, return_tensors=\"pt\", max_length=512, truncation=True)\n","    tokenized_text = tokenized_text.to(device)\n","    summary_ids = model1.generate(tokenized_text, max_length=max_length, min_length=5, length_penalty=2.0, num_beams=4, early_stopping=True)\n","    summary = tokenizer1.decode(summary_ids[0], skip_special_tokens=True)\n","\n","    return summary"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_name = \"facebook/bart-large-cnn\"\n","tokenizer2 = BartTokenizer.from_pretrained(model_name)\n","model2 = BartForConditionalGeneration.from_pretrained(model_name)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model2.to(device)\n","\n","\n","def generate_summary_bart(input_text):\n","    inputs = tokenizer2(input_text, return_tensors=\"pt\", max_length=1024, truncation=True).to(\"cuda\")\n","    summary_ids = model2.generate(inputs['input_ids'], \n","                                 max_length=80, \n","                                 min_length=5, \n","                                 length_penalty=2.0, \n","                                 num_beams=4, \n","                                 early_stopping=True)\n","    summary = tokenizer2.decode(summary_ids[0], skip_special_tokens=True)\n","    return summary\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_name = \"google/pegasus-large\"\n","tokenizer3 = PegasusTokenizer.from_pretrained(model_name)\n","model3 = PegasusForConditionalGeneration.from_pretrained(model_name)\n","\n","\n","def generate_summary_pegasus(input_text, max_input_length=1024, max_summary_length=60, min_summary_length=15):\n","    inputs = tokenizer3(input_text, return_tensors=\"pt\", max_length=max_input_length, truncation=True)\n","    summary_ids = model3.generate(inputs['input_ids'], \n","                                 max_length=max_summary_length,\n","                                 min_length=min_summary_length,  \n","                                 num_beams=4, \n","                                 length_penalty=2.0, \n","                                 early_stopping=True)\n","    summary = tokenizer3.decode(summary_ids[0], skip_special_tokens=True)\n","    return summary"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["path=\"/kaggle/input/bsebse/BSE102_Lecture 3_Chemical basis of life.pdf\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["input_text=process_text_in_sentence_chunks(path,512)\n","for text in input_text:\n","    print(generate_summary_t5(text))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["input_text=process_text_in_sentence_chunks(path,900)\n","for text in input_text:\n","    print(generate_summary_bart(text))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["input_text=process_text_in_sentence_chunks(path,512)\n","for text in input_text:\n","    print(generate_summary_pegasus(text))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5289950,"sourceId":8797460,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
