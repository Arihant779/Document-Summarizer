{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-XUi9KEStJAi",
        "outputId": "911acfdb-3903-4f43-c306-db562fd02cda"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install langchain-core\n",
        "!pip install langchain-community\n",
        "!pip install chromadb\n",
        "!pip install --q chromadb\n",
        "!pip install --q langchain-text-splitters\n",
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!ollama pull mxbai-embed-large\n",
        "!ollama pull mistral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3KwqgeEyLVV"
      },
      "outputs": [],
      "source": [
        "from langchain_community.llms import ollama\n",
        "from langchain_community.embeddings import OllamaEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_community.chat_models import ChatOllama\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NkwFfJXyOMd"
      },
      "outputs": [],
      "source": [
        "def file_preprocessing(file):\n",
        "    loader =  PyPDFLoader(file)\n",
        "    pages = loader.load()\n",
        "    return pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-jaSmyGyc40"
      },
      "outputs": [],
      "source": [
        "data = file_preprocessing(\"/home/arunav/Downloads/Adolf Hitler Biography.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOsrdVX0yguV"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "chunks = text_splitter.split_documents(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AQkrl26_yvZH",
        "outputId": "520b2d09-54bc-4443-c879-a83d6f42be11"
      },
      "outputs": [],
      "source": [
        "vector_db = Chroma.from_documents(\n",
        "    documents=chunks,\n",
        "    embedding=OllamaEmbeddings(model=\"mxbai-embed-large\",show_progress=True),\n",
        "    collection_name=\"local-rag\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_HppT5Ly2s5"
      },
      "outputs": [],
      "source": [
        "local_model = \"mistral\"\n",
        "llm = ChatOllama(model=local_model)\n",
        "QUERY_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"\"\"You are an AI language model assistant. Your task is to generate five\n",
        "    different versions of the given user question to retrieve relevant documents from\n",
        "    a vector database. By generating multiple perspectives on the user question, your\n",
        "    goal is to help the user overcome some of the limitations of the distance-based\n",
        "    similarity search. Provide these alternative questions separated by newlines.\n",
        "    Original question: {question}\"\"\",\n",
        ")\n",
        "retriever = MultiQueryRetriever.from_llm(\n",
        "    vector_db.as_retriever(),\n",
        "    llm,\n",
        "    prompt=QUERY_PROMPT\n",
        ")\n",
        "\n",
        "template = \"\"\"Answer the question in points based ONLY on the following context:\n",
        "{context}\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SB9eMBa1y5So"
      },
      "outputs": [],
      "source": [
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYaGy8OoOP_O"
      },
      "outputs": [],
      "source": [
        "que = \"\"\"\n",
        "what were the impacts of hitler in german patriotism?\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "d9L8RP6by6dg",
        "outputId": "5221b3b0-78c9-4975-924a-f17d2a54211f"
      },
      "outputs": [],
      "source": [
        "print(chain.invoke(que))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vector_db.delete_collection()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
